\documentclass[../../doc.tex]{subfiles}

\begin{document}
    \subsection{Описание метода}

    Существует два базовых метода для решения задач нелинейных задач оптимального управления, к классу которых относится задача \eqref{eq:discrete-system}-\eqref{eq:discrete-cost}:
    \begin{enumerate}\itemsep0em
        \item Метод дифференциального динамического программирования (DDP) \cite{mayne1966}, \cite{murray1984};
        \item Метод итеративного линейно-квадратичного регулятора (iLQR\footnote{В некоторых источниках, например~\cite{sideris2005}, используется аббревиатура SLQ.}) \cite{li2004}.
    \end{enumerate}
    Методы идейно схожи:
    \begin{enumerate}\itemsep0em
        \item Методы итеративны и используют полную информацию о состоянии системы\footnote{Наличие уравнения наблюдения предполагало бы, что каждая итерация алгоритма проводится не на компьютере, а не реальном объекте. Применительно к нашей модели это означает, что человек достигнет цели движения только с некоторой попытки.};
        \item На каждой итерации методы используют некоторое \textit{референсное} управление $\bar u$ и соответствующую ему референсную траекторию $\bar x$;
        \item Вдоль референсной траектории задача полиномиально аппроксимируются;
        \item На основании аппроксимированной системы строится некоторая поп\-равка на исходное референсное управление.
    \end{enumerate}

    \begin{definition}
        Под \textit{референсным управлением} $\bar u$ мы будем понимать управление, которое подается на вход каждой итерации соответствующего алгоритма.
        Под \textit{референсной траекторей}~--- соответствующую референсному управлению траекторию системы $\bar x$, либо иногда пару $(\bar u, \bar x)$.
    \end{definition}

    Отличие методов заключается в способе получения оптимальной поправки:
    метод DDP cтроит поправку как градиент гамильтониана аппроксимированной задачи
    $$
        \delta u^k = \alpha \nabla_u H(\bar u^k),
    $$
    метод iLQR~--- как её линейно-квадратичный регулятор.

    Считается, что метод iLQR более надежный,
    так как в меньшей степени подвержен проблемам,
    присущим градиентным методам,
    таким как остановка в локальном минимуме,
    но сходится за большее число итераций, чем метод DDP.
    Однако при проведении численного эксперимента для сравнения скорости сходимости на конкретных задачах авторы приходят к противоположным результатам.
    Лучше всего резюмирует это положение вещей работа~\cite{manchester2016}, в которой проведено сравнение двух методов для трёх классических задач механики, и в каждой задаче методы показывают разную асимптотику сходимости.

    В данной работе для построения управления был выбран метод iLQR. Выпишем его основные шаги:
    \begin{enumerate}\itemsep0em
        \item На каждой итерации имеем референсную траекторию $(\bar u, \bar x)$;
        \item Вдоль референсной траектории линеаризуем задачу Коши и аппроксимируем функционал качества до второго порядка;
        \item Строим поправку на управление $\delta u$ как линейно-квадратичный регулятор аппроксимированной задачи;
        \item Если не выполнено терминальное условие
            \begin{equation}
                \left|J(\bar u) - J(\bar u + \delta u)\right| < \varepsilon,
            \end{equation}
            то используем поправленное управление $\bar u + \delta u$ в качестве референсного на следующей итерации алгоритма.
            
    \end{enumerate}

    \ifSubfilesClassLoaded{
        \nocite{*}
        \clearpage
        \bibliographystyle{plain}
        \bibliography{../../refs}
    }{}
\end{document}